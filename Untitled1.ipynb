{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e96180",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_24236/2239274614.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Szymon\\AppData\\Local\\Temp/ipykernel_24236/2239274614.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    Whatch out - there are a few intentional typos in pseudocode to encourage you to read the code.\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "![](https://codimd.s3.shivering-isles.com/demo/uploads/upload_489b831f1d02ec3bc1880546876d59e6.png)\n",
    "# Digit recogniser pseudocode\n",
    "Whatch out - there are a few intentional typos in pseudocode to encourage you to read the code.\n",
    "In a few other places, arguments are replaced with ```???``` - it's your task to give them values.\n",
    "\n",
    "## -1. Importing libraries\n",
    "```import tensorflow as ts ``` [a python library for machine learning](https://www.tensorflow.org/overview)\n",
    "```from tensorflow import keras``` [a 'sublibrary' of tensorflow more specifically designed for neural networks](https://keras.io/getting_started/)\n",
    "```from keras.datasets import mnist``` [MNIST dataset with labeled, handwritten digits](http://yann.lecun.com/exdb/mnist/)\n",
    "```!pip install pandas``` If we don't have pandas installed yet, it will be installed now\n",
    "```import pandas as pd``` We'll use [pandas (a data analysis library)](https://pandas.pydata.org/) to plot how well the model did during training\n",
    "```!pip install matplotlib```\n",
    "```import matplotlib.pyplot as plt``` We'll use [matplotlib - a data visualization library](https://matplotlib.org/) for plotting digits images\n",
    "\n",
    "\n",
    "## 0. Preparing the data\n",
    "```(train_in_pre, train_out_pre), (test_in_pre, test_out_pre) = mnist.load_data()```\n",
    "We get training images and their labels, as well as testing images and their labels. ```train_in_pre``` and ```test_in_pre``` are arrays of images. Each image is a 28x28 arrays of pixels (each pixel is a number between 0 and 255, which represents its lightness). ```train_out_pre``` and ```test_out_pre``` are arrays of labels - the values of drawn digits.\n",
    "\n",
    "Use ```print(train_in_pre[5])``` to see how a single digit's reprezentation looks like and ```print(train_in_pre[5])``` to see how a single label looks like.\n",
    "\n",
    "Convert images into arrays of 784 pixels:\n",
    "```python=\n",
    "all_input = []\n",
    "all_output = []\n",
    "test_in = []\n",
    "test_out = []\n",
    "\n",
    "for i in range(len(train_in_pre)):\n",
    "    new = []\n",
    "    for j in range(30):\n",
    "        new += train_in_pre[i][j].tolist()\n",
    "    all_input += [new]\n",
    "\n",
    "for i in range(len(test_in_pre)):\n",
    "    new = []\n",
    "    for j in range(30):\n",
    "        new += test_in_pre[i][j].tolist()\n",
    "    test_in += [new]\n",
    "```\n",
    "\n",
    "Convert outputs from a single label with the digit's value to an array of ten numbers: nine 0 and one 1, on the position denoting the digit's label:\n",
    "```python=\n",
    "for i in range(len(train_out_pre)):\n",
    "    all_output += [[(1 if train_out_pre[i] == j else 0) for j in range(10)]]\n",
    "\n",
    "for i in range(len(test_out_pre)):\n",
    "    test_out += [[(1 if test_out_pre[i] == j else 0) for j in range(10)]]\n",
    "```\n",
    "\n",
    "Split the all training data into actual training data and validation:\n",
    "```python=\n",
    "val_in = all_input[0:2000]\n",
    "train_in = all_input[2000:]\n",
    "val_out = all_output[0:2000]\n",
    "train_out = all_output[2000:]\n",
    "```\n",
    "\n",
    "#### A function for displaying an image of a digit\n",
    "(It expects to get an array of 784 pixels)\n",
    "```python=\n",
    "def plot_digit(image):\n",
    "    pixels = []\n",
    "    for i in range(28):\n",
    "        pixels += [image[28*i : 28*(i+1)]]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(pixels)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_digit(train_in[0])\n",
    "```\n",
    "\n",
    "\n",
    "## 1. Declaring a neural network\n",
    "\n",
    "#### Declaring a typical layer in neural network\n",
    "```python=\n",
    "keras.layers.Dense(\n",
    "    units=?????,\n",
    "    activation='relu',\n",
    "    input_shape=[784]\n",
    ")\n",
    "```\n",
    "```units```: How many neurons we want in this layer\n",
    "```activation```: The activation function, inside a neuron, which transforms its input before passing it to its output. We use the activation function in all layers besides the last one (output layer)\n",
    "```input_shape```: Shape of external data received by a layer. We use it only in the first layer, which receives data\n",
    "\n",
    "#### [optional] Special layers\n",
    "```keras.layers.BatchNormalization()```\n",
    "[Batch Normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)\n",
    "```keras.layers.Drouput(rate = ???)```\n",
    "[Droupout - one of ways to minimize overfitting](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "\n",
    "#### Declaring a neural network\n",
    "```neural_net = keras.Sequential([???])```\n",
    "Pass an array of layers - remember that the first one should be input layer and the last one should be an output layer.\n",
    "\n",
    "## 2. Compiling the model\n",
    "At this point, we specify 'meta functions' for a model, which influence how it will be trained.\n",
    "```python=\n",
    "net_neural.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "```optimizer```: Choose an algorithm for looking for the maximum. Determines how we update the model based on the data and loss function. We'll use adam here.\n",
    "```loss```: The measure of how inaccurate the model is on a given piece of data (e. g. a single digit).\n",
    "```metrics```: Used to monitor how the training is going. Here we use accuracy, the fraction of correctly classified digits.\n",
    "\n",
    "\n",
    "## 3. Training the model\n",
    "```python=\n",
    "history = neural_net.fit(\n",
    "    train_in,\n",
    "    train_out,\n",
    "    validation_data=(in_val, out_val),\n",
    "    batch_size=???,\n",
    "    epochs=???,\n",
    "    verbose=1,\n",
    "    callbacks=[???]\n",
    ")\n",
    "```\n",
    "\n",
    "The first two parameters: an array of input data for training - the images of digits and an array of output data for training - the labels of digits.\n",
    "```validation_data```: The validation data used to measure, how well the model is doing. As a first parameter pass an array of input data, as the second - an array of output data. (Why don't we want to use training data here? Why don't we want to use test data here?)\n",
    "```batch_size```: How many pieces of data we want to feed to the model before adjusting it each time.\n",
    "```epochs```: How many times we want the model to see each piece of data from the input before we finish training.\n",
    "For more intuition on choosing batch_size and epochs, [check out graphs from here.](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/)\n",
    "```verbose``` : Print log how the training is going.\n",
    "```callbacks```: Optional parameter - check out below.\n",
    "\n",
    "#### [optional] Possible callbacks\n",
    "```keras.callbacks.EarlyStopping()``` [Early stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
    "```keras.callbacks.ReduceLROnPlateu()``` [Reduce learning rate on plateu](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau)\n",
    "\n",
    "\n",
    "## 4. Summing up, check how the model did during training\n",
    "Transform the history of training into a different format - a pandas dataframe:\n",
    "```history = pd.DataFrame(history.history)```\n",
    "\n",
    "Plot, how well the model did on training data (binary_accuracy) and validation data (val_binary_accuracy) during the training:\n",
    "```history.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()```\n",
    "\n",
    "See the model's predictions for a single image:\n",
    "```print(neural_net.predict([test_in[0], test_in[1]]))```\n",
    "\n",
    "\n",
    "## 5. Evaluate the model\n",
    "Test the model on previously unsees data:\n",
    "```test_loss, test_acc = neural_net.evaluate(test_in, test_out, verbose=2)```\n",
    "\n",
    "## 6. Your task\n",
    "1. Play around with the code: see, what happens at each stage (you can e. g. print values of parameters / variables to see better what happens) and make it work and recognise hand-written digits.\n",
    "2. One of the reasons the model works rather slowly is a large size of input data: 784. How about making it smaller, but in such a way that the digits are still 'recogniseable'?\n",
    "3. Try playing around with the model's parameters and arguments (you can start from [optional] sections) to improve it.\n",
    "4. How about preprocessing the image in some way? Do you think that e. g. changing colours of pixels (either to 0 or 1, depending on wether they are bright enough) can improve the model? Also, the same digits on different images can have different sizes (either height/width or thickness) or be drawn in different positions. What can we do about that to further improve the model?\n",
    "\n",
    "![](https://codimd.s3.shivering-isles.com/demo/uploads/upload_7a266a7ea56523ab1e80111cfa2ae450.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c5903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
